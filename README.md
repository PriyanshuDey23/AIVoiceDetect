
# AI vs Voice Audio Detection 

This Streamlit-based web application allows users to upload an audio file, which is then analyzed by the Gemini model to detect whether the audio is AI-generated or voice-generated.

## Features
- **Audio Upload**: Users can upload audio files in MP3, WAV, or FLAC formats.
- **AI Detection**: The model uses the Gemini API to analyze the audio and determine if it's generated by AI or a real voice.
- **Real-time Feedback**: Users receive immediate feedback on the nature of the uploaded audio (AI-generated or voice-generated).

## Installation

### Prerequisites

- Python 3.9+
- An active [Google Gemini API](https://aistudio.google.com/apikey) key
- `gemini-api` library installed
- Streamlit installed

### Setup

1. Clone the repository:

    ```bash
    git clone https://github.com/PriyanshuDey23/AIVoiceDetect.git
    cd ai-voice-detection
    ```

2. Install the required dependencies:

    ```bash
    pip install -r requirements.txt
    ```

    Where `requirements.txt` includes:
    ```text
    streamlit
    google-generativeai
    requests
    ```

3. Set up your Gemini API key:

    - Go to the [Google Gemini API](https://aistudio.google.com/apikey).
    - Navigate to  create a new API key.
    - Set the environment variable `GEMINI_API_KEY`:

    ```bash
    export GEMINI_API_KEY="your-gemini-api-key"
    ```

4. Run the Streamlit app:

    ```bash
    streamlit run app.py
    ```

5. Visit `http://localhost:8501` in your browser to start using the application.

## How It Works

1. **Audio Upload**: Users can upload an audio file in MP3, WAV, or FLAC format.
2. **Gemini Model Integration**: The audio file is sent to the Gemini model for analysis via the `google.generativeai` library.
3. **Detection**: The model detects if the audio is **AI-generated** or **voice-generated** and returns the result.
4. **Display**: The result is shown to the user in the Streamlit interface.

## Usage

1. Open the app in your browser after starting it locally with Streamlit.
2. Upload an audio file (MP3, WAV, or FLAC).
3. Wait for the model to analyze the audio, and the result will be displayed.

### Example Outputs:
- **AI-generated**: The model detects that the uploaded audio is AI-generated.
- **Voice-generated**: The model detects that the uploaded audio is generated by a human voice.
- **Error**: If the model cannot determine the audio type, an error message will be shown.

## Contributing

Contributions are welcome! If you encounter any issues or have suggestions for improvements, please open an issue or submit a pull request.

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
